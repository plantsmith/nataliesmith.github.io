[
  {
    "objectID": "portfolio.html",
    "href": "portfolio.html",
    "title": "Portfolio",
    "section": "",
    "text": "Tracking PM2.5 Trends in Los Angeles\n\n\n\nTrends\n\n\n\nAn overview of how I created a data-driven infographic on PM2.5 levels in Los Angeles (2010‚Äì2024), from data analysis in R Studio to design refinement in Affinity Designer\n\n\n\nNatalie Smith\n\n\nMar 5, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nTradeoffs of Green Investing\n\n\n\nModeling\n\n\nEconomics\n\n\n\nMonte Carlo simulation of 100 investment portfolios to assess the financial and environmental performance of green versus brown investments\n\n\n\nNatalie Smith\n\n\nDec 3, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAilanthus altissima: Strategies for Control and Management in California\n\n\n\nGIS\n\n\nModeling\n\n\n\nGIS-based spatial analysis study using MaxEnt predictive modeling, incorporating climate variables and species occurrence data\n\n\n\nNatalie Smith and Priscilla Ta\n\n\nSep 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nQuantifying the Value of Wetland Restoration\n\n\n\nModeling\n\n\nEconomics\n\n\n\nEstimating restoration costs and storm protection benefits for 60 hectares of salt marsh using benefit transfer and predictive modeling.\n\n\n\nNatalie Smith\n\n\nSep 25, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMapping Sea Lion Conservation: Identifying Hotspots and Coldspots\n\n\n\nGIS\n\n\n\nGIS Analysis of California Sea Lion and Steller Sea Lion Distribution and Threats\n\n\n\nNatalie Smith & Madi Calbert\n\n\nSep 20, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAnalyzing Socioeconomic and Environmental Factors in LA\n\n\n\nTrends\n\n\n\nExamining correlations between socioeconomic status, environmental factors, and historical redlining grades in Los Angeles using Principal Components Analysis (PCA)\n\n\n\nNatalie Smith\n\n\nMar 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nAir,NYC: Mapping the Concrete Jungle\n\n\n\nGIS\n\n\nTrends\n\n\n\nAnalyzing air pollution levels in New York City between 2020 and 2021 with ArcGIS through census and zoning data.\n\n\n\nNatalie Smith and Sam Lance\n\n\nMar 12, 2024\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPredicting Palmetto Species with Binary Logistic Regression\n\n\n\nModeling\n\n\n\nApplying binary logistic regression to predict Palmetto species and evaluating model performance through repeated cross-validation\n\n\n\nNatalie Smith\n\n\nMar 7, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding Adult Fish Passage Dynamics at Willamette Falls\n\n\n\nTrends\n\n\n\nTime series and seasonality analysis of adult passage for Coho, Jack Coho, and Steelhead from 2001 to 2010.\n\n\n\nNatalie Smith\n\n\nJan 30, 2024\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "portfolio/palms/index.html",
    "href": "portfolio/palms/index.html",
    "title": "Predicting Palmetto Species with Binary Logistic Regression",
    "section": "",
    "text": "1 Overview:\nThe palmetto data examines the survival, growth, and biomass estimates of two dominant palmetto species, Serenoa repens and Sabal etonia, in south Florida from 1981 to 2017, recorded at 5-year intervals. The dataset encompasses various variables, but for this analysis, we will focus on canopy height, length, and width, as well as green leaves.\nWe aim to create two models with different predictor variables and the better-performing model will be selected. We will then evaluate the success of the chosen model in correctly classifying a plant species.\n\n\n\nLeft: Sabal etonia, Right: Serenoa repens\n\n\n\n\n2 Exploratory Plots:\nFirst we want to explore differences in the two species based on canopy height, canopy length, canopy width, and green leaves.\n\n2.0.1 Add Libraries:\n\n\nCode\nlibrary(tidyverse) \nlibrary(here)\nlibrary(tidymodels) \nlibrary(ggplot2)\nlibrary(patchwork)\nlibrary(broom)\nlibrary(kableExtra)\n\n\n\n\n2.0.2 Import and Wrangle Data:\n\n\nCode\n#pull in the data\np_df &lt;- read.csv(here(\"portfolio/palms/data/palmetto.csv\"))\n\n#clean data\npalmetto &lt;- p_df %&gt;%\n  select(species,height,length,width,green_lvs) %&gt;% \n  mutate(species=as_factor(species)) %&gt;% \n  drop_na()\n\n\n\n\n2.0.3 Plots:\n\n\nCode\n#Species Boxplot ~ Green Leaves\nleaves_plot &lt;- ggplot(palmetto, \n                     aes(x =as.factor(species),\n                         y = green_lvs)) +\n  geom_boxplot(fill = \"#ADD8E6\", color = \"#2E75B6\",\n               alpha = 0.8, \n               outlier.color = \"#FF5733\",\n               outlier.shape = 16, \n               outlier.size = 1) +  \n  scale_x_discrete(labels =\n                     expression(italic(\"S.repens\"),\n                                italic(\"S.etonia\"))) + \n  labs(x = \"Species\", y = \"Green Leaves\") +\n  theme_minimal() +\n  theme(\n    axis.title.y = element_text(size = 10),\n    axis.title.x = element_text(size = 10),\n    axis.text = element_text(size = 10),\n    legend.position = \"none\"\n  )\n# leaves_plot\n\n\n\n\nCode\n#Species Boxplot ~ Canopy Height\nheight_plot &lt;- ggplot(palmetto, \n                     aes(x =as.factor(species),\n                         y = height)) +\n  geom_boxplot(fill = \"#ADD8E6\", color = \"#2E75B6\",\n               alpha = 0.8, \n               outlier.color = \"#FF5733\",\n               outlier.shape = 16, \n               outlier.size = 1) +  \n  scale_x_discrete(labels =\n                     expression(italic(\"S.repens\"),\n                                italic(\"S.etonia\"))) + \n  labs(x = \"Species\", y = \"Canopy Height\") +\n  theme_minimal() +\n  theme(\n    axis.title.y = element_text(size = 10),\n    axis.title.x = element_text(size = 10),\n    axis.text = element_text(size = 10),\n    legend.position = \"none\"\n  )\n# height_plot\n\n\n\n\nCode\n#Species Boxplot ~ Canopy Length\nlength_plot &lt;- ggplot(palmetto, \n                     aes(x =as.factor(species),\n                         y = length)) +\n  geom_boxplot(fill = \"#ADD8E6\", color = \"#2E75B6\",\n               alpha = 0.8, \n               outlier.color = \"#FF5733\",\n               outlier.shape = 16, \n               outlier.size = 1) +  \n  scale_x_discrete(labels =\n                     expression(italic(\"S.repens\"),\n                                italic(\"S.etonia\"))) + \n  labs(x = \"Species\", y = \"Canopy Length\") +\n  theme_minimal() +\n  theme(\n    axis.title.y = element_text(size = 10),\n    axis.title.x = element_text(size = 10),\n    axis.text = element_text(size = 10),\n    legend.position = \"none\"\n  )\n# length_plot\n\n\n\n\nCode\n#Species Boxplot ~ Canopy Width\nwidth_plot &lt;- ggplot(palmetto, \n                     aes(x =as.factor(species),\n                         y = width)) +\n  geom_boxplot(fill = \"#ADD8E6\", color = \"#2E75B6\",\n               alpha = 0.8, \n               outlier.color = \"#FF5733\",\n               outlier.shape = 16, \n               outlier.size = 1) +  \n  scale_x_discrete(labels =\n                     expression(italic(\"S.repens\"),\n                                italic(\"S.etonia\"))) + \n  labs(x = \"Species\", y = \"Canopy Width\") +\n  theme_minimal() +\n  theme(\n    axis.title.y = element_text(size = 10),\n    axis.title.x = element_text(size = 10),\n    axis.text = element_text(size = 10),\n    legend.position = \"none\"\n  )\n# width_plot\n\n\n\n\n2.0.4 Combined Plot:\n\n\nCode\nplot1 &lt;- leaves_plot + \n  theme(axis.text.y = element_text(size = 8)) +\n  theme(axis.title.x = element_blank())\n\nplot2 &lt;- height_plot +\n  theme(axis.text.y = element_text(size = 8)) +\n  theme(axis.title.x = element_blank())\n\nplot3 &lt;- length_plot +\n  theme(axis.text.y = element_text(size = 8)) +\n  theme(axis.title.x = element_blank())\n\nplot4 &lt;- width_plot +\n  theme(axis.text.y = element_text(size = 8)) +\n  theme(axis.title.x = element_blank())\n\n\nBased on our visual exploration, we can see that while the species are very similar, there are species differentiation observed when examining green leaves and canopy length.\n\n\nCode\ncombinedplot &lt;- plot1 + plot2 + plot3 + plot4\ncombinedplot\n\n\n\n\n\n\n\n\nFigure¬†1: Comparison of species Sabal etonia and Serenoa repens reveals differences and similarities in predictor variables. In combined boxplots, (counter-clockwise from left) we observe a higher count of green leaves in S. repens. In canopy length, we see greater canopy length in S. etonia. Canopy width and height exhibit similar counts.\n\n\n\n\n\n\n\n\n3 Models:\nTo determine whether a plant is Serenoa repens or Sabal etonia, we need to conduct a binary logistic regression using several predictor variables. We will perform the analysis twice comparing the following models:\n\nModel 1: The log odds of plant type using plant height, canopy length, canopy width, and green leaves as predictor variables.\nModel 2: The log odds of plant type using plant height, canopy width, and green leaves (excluding canopy length for this model).\n\nNote that S. repens = speices 1 and S. etonia = species 2.\n\n\nCode\n# Define formulas:\nf1 &lt;- species ~ height + length + width + green_lvs\nf2 &lt;- species ~ height + width + green_lvs\n\n# BLR:\nblr1 &lt;- glm(formula = f1, data = palmetto, family = binomial)\n\nblr2 &lt;- glm(formula = f2, data = palmetto, family = binomial)\n\n# # Summarize:\n# summary(blr1)\n# summary(blr2)\n\n\nThe coefficients from the binary logistic regression analysis offer insights into the log odds of the predictor variables. In model f1, all predictors have p-values &lt; 0.5, indicating significance. However, upon removing canopy height from the model in f2, the p-value for height is &gt; 0.5, suggesting it is no longer a suitable predictor variable. Additionally, Model f1 presents an AIC of 5194.6, while f2 shows an AIC of 5987.5, indicating that f1 is the preferred model.\n\n\n4 Repeated Cross Validation:\nNext we need to utilize repeated cross-validation (ten-fold cross-validation) using tidymodels for both models.\n\n\nCode\n# Set seed\nset.seed(10101)\n\n# Create folds:\nsurv_folds &lt;- vfold_cv(palmetto, v = 10, repeats = 10)\n\n# Default: \nblr_mdl &lt;- logistic_reg() %&gt;%\n  set_engine('glm') \n\n# Workflows:\nblr_wf1 &lt;- workflow() %&gt;%  \n  add_model(blr_mdl) %&gt;%\n  add_formula(f1)\n\nblr_wf2 &lt;- workflow() %&gt;%  \n  add_model(blr_mdl) %&gt;%\n  add_formula(f2)\n\n#apply to folded datasetls: \nblr_fit_folds1 &lt;- blr_wf1 %&gt;%\n  fit_resamples(surv_folds)\n\nblr_fit_folds2 &lt;- blr_wf2 %&gt;%\n  fit_resamples(surv_folds)\n\n# blr_fit_folds1\n# blr_fit_folds2\n\n# # Metrics:\n# collect_metrics(blr_fit_folds1)\n# collect_metrics(blr_fit_folds2)\n\n\nThe metrics show:\n\nF1 has a mean accuracy of approximately 92% and a mean ROC of approximately 97%.\nF2 has a mean accuracy of approximately 90% and a mean ROC of approximately 96%.\n\nBased on these metrics, F1 appears to be the better performing model, as it has higher values for both accuracy and ROC.\n\n\n5 Train on Full Dataset:\nNow that we have decided the F1 is the better predicting model, we want to train the model on the entire dataset.\n\n\nCode\nblr_fit_full &lt;- blr_mdl %&gt;%\n  fit(formula = f1, data = palmetto)\n\npalmetto_predict &lt;- palmetto %&gt;% \n  mutate(predict(blr_fit_full,new_data = .))\n\n\nThe results of the BLR model are presented below:\n\n\nCode\n# Broom::Tidy \ntidy_output &lt;- tidy(blr_fit_full)\n\n# Create kable table with title\ncoef_table &lt;- kable(tidy_output, align = \"c\")%&gt;%\n  kable_styling() \n\ncoef_table\n\n\n\n\n\n\n\n\nterm\n\n\nestimate\n\n\nstd.error\n\n\nstatistic\n\n\np.value\n\n\n\n\n\n\n(Intercept)\n\n\n3.2266851\n\n\n0.1420708\n\n\n22.71180\n\n\n0\n\n\n\n\nheight\n\n\n-0.0292173\n\n\n0.0023061\n\n\n-12.66984\n\n\n0\n\n\n\n\nlength\n\n\n0.0458233\n\n\n0.0018661\n\n\n24.55600\n\n\n0\n\n\n\n\nwidth\n\n\n0.0394434\n\n\n0.0021000\n\n\n18.78227\n\n\n0\n\n\n\n\ngreen_lvs\n\n\n-1.9084747\n\n\n0.0388634\n\n\n-49.10728\n\n\n0\n\n\n\n\n\n\nFigure¬†2: Binary logistic regression results for the F1 model applied to the entire Palmetto dataset.\n\n\n\n\nTo assess the model‚Äôs accuracy for identifying plant species correctly, we need to introduce a conditional argument: if the predicted probability is greater than or equal to 50%, the plant is classified as species 1; otherwise, it is classified as species 2. We can then construct a table illustrating the count of correctly and incorrectly classified plants from the original dataset by the model, as well as a column displaying the percentage of plants correctly classified.\n\n\nCode\n# Calculate predicted species based on probabilities and 50% cutoff\npalmetto_predict_prob&lt;- augment(blr_fit_full, new_data = palmetto, type.predict = 'response') %&gt;% \n    mutate(predicted_species = ifelse(.pred_1 &gt;= 0.5, \"1\", \"2\")) %&gt;%\n  select(predicted_species, everything())\n\n\n\n\nCode\n# Create a table of observed and predicted species\n\n# results_table &lt;- table(palmetto_predict_prob %&gt;% \n#   select(predicted_species, species))\n# \n# tidy(results_table)\n\nspecies &lt;- c('S. Repens', 'S. Etonia')\npredict_correct &lt;- c(5548,5701)\npredict_incorrect &lt;- c(564,454)\npercent_correct &lt;- c(91,93)\n\n# Create the data frame\nspecies_correct &lt;- data.frame(species, predict_correct, predict_incorrect, percent_correct)\n\n#kable it\nspecies_correct_kable &lt;- kable(species_correct, align = \"c\") %&gt;%\n  kable_styling() \n\nspecies_correct_kable\n\n\n\n\n\nspecies\npredict_correct\npredict_incorrect\npercent_correct\n\n\n\n\nS. Repens\n5548\n564\n91\n\n\nS. Etonia\n5701\n454\n93\n\n\n\n\n\n\n\n\n\n6 Reference:\nAbrahamson, W.G. 2019. Survival, growth and biomass estimates of two dominant palmetto species of south-central Florida from 1981 - 2017, ongoing at 5-year intervals ver 1. Environmental Data Initiative. https://doi.org/10.6073/pasta/f2f96ec76fbbd4b9db431c79a770c4d5"
  },
  {
    "objectID": "portfolio/benefits_transfer/index.html",
    "href": "portfolio/benefits_transfer/index.html",
    "title": "Quantifying the Value of Wetland Restoration",
    "section": "",
    "text": "Coastal wetlands are essential in providing protection against storm surges and mitigating the effects of sea-level rise. These ecosystems function as natural sponges, absorbing wave energy and significantly reducing flood risk. This report evaluates the economic value of restoring 60 hectares of salt marsh in Huntington Beach, California, employing a benefits transfer analysis.\n\n\n\nPhoto from Huntington Beach Wetlands Conservancy"
  },
  {
    "objectID": "portfolio/benefits_transfer/index.html#exploring-marginal-costs",
    "href": "portfolio/benefits_transfer/index.html#exploring-marginal-costs",
    "title": "Quantifying the Value of Wetland Restoration",
    "section": "Exploring Marginal Costs",
    "text": "Exploring Marginal Costs\nTo determine the marginal cost of restoring each additional hectare, I analyzed the data using a scatter plot with hectares on the y-axis and total restoration costs on the x-axis for projects in the USA.\n\n\nCode\n#filter wetland df to only include USA\nwetland_usa &lt;- wetland_df %&gt;% \n  filter(country==\"USA\")\n\n# Scatter plot with log-transformed axes\nggplot(wetland_usa, aes(x = total_cost_2010, y =area_ha)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE) +\n  scale_x_log10() +  # Log transform x-axis\n  scale_y_log10() +  # Log transform y-axis\n  labs(title = \"Total Restoration Costs by Saltmarsh Area\",\n       x = \"Saltmarsh Area (ha, log scale)\",\n       y = \"Total Restoration Costs (USD2010, log scale)\") +\n  theme_bw()\n\n\n\n\n\nFigure 1: Scatterplot illustrating the relationship between total restoration costs and salt marsh area restored, using log-transformed variables.\n\n\n\n\nThe scatterplot, which features log-transformed variables to better visualize the trends, illustrates a positive trend between total restoration costs and the area of saltmarsh restored, though the relationship isn‚Äôt strictly linear. The costs fluctuate suggesting that the marginal cost per additional hectare isn‚Äôt constant."
  },
  {
    "objectID": "portfolio/benefits_transfer/index.html#regression-analysis",
    "href": "portfolio/benefits_transfer/index.html#regression-analysis",
    "title": "Quantifying the Value of Wetland Restoration",
    "section": "Regression Analysis",
    "text": "Regression Analysis\nBased on the aformentioned studies, a regression model (total_cost_2010 = a + b*area_ha + error) was used to refine the cost estimate for 60 hectares.\n\n\nCode\n# run regression\nlm_cost &lt;- lm(total_cost_2010 ~ area_ha, data = wetland_usa)\n\n# display results\nsummary(lm_cost)\n\n\n\nCall:\nlm(formula = total_cost_2010 ~ area_ha, data = wetland_usa)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-5239511  -541661  -352808    87971  7111292 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   446092     368986   1.209    0.234    \narea_ha        43861       7093   6.183 3.55e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2011000 on 37 degrees of freedom\nMultiple R-squared:  0.5082,    Adjusted R-squared:  0.4949 \nF-statistic: 38.23 on 1 and 37 DF,  p-value: 3.546e-07\n\n\n\n\nCode\n# recalculate total cost with 60 ha of wetland\nhb_cost &lt;- predict(lm_cost, data.frame(area_ha = 60))\n# hb_cost\n\n\nThe regression model estimates the restoration cost for 60 hectares at $3,077,755. However, ncorporating variables like ecological complexity could improve cost accuracy."
  },
  {
    "objectID": "portfolio/benefits_transfer/index.html#avoiding-estimated-damages",
    "href": "portfolio/benefits_transfer/index.html#avoiding-estimated-damages",
    "title": "Quantifying the Value of Wetland Restoration",
    "section": "Avoiding Estimated Damages",
    "text": "Avoiding Estimated Damages\nAn estimate of avoided damages was calculated using a benefits transfer approach. By applying the elasticity of damages with respect to wetland area (-0.236), which was derived from existing studies, we can estimate the impact of restoring additional wetlands. Given the current wetland area of 72 hectares and the potential expansion by 60 hectares, with total storm damages amounting to $18 million, the benefits transfer method predicts that restoring 60 hectares of wetlands would avoid approximately $2.4 million in economic damages during storms like Hurricane Hilary.\n\n\nCode\n#ln(damages/GDP) = -7.992 - 0.236ln(wetlands) + 3.298ln(wind speed) - \n#0.55ln(speed) + 0.137(volume) - 0.058(time)\n\n#calculate change in wetland \ncurrent_wetland_area &lt;- 72\nadditional_wetland_area &lt;- 60\ntotal_wetland_area &lt;- current_wetland_area + additional_wetland_area \n# 72 + 60 = 132\n\n\nln_wetland &lt;- log(total_wetland_area/current_wetland_area)\n# ln_wetland\n#log(132/72) = 0.6061358034\n\n#reduction in damages\nln_damages &lt;- -0.236 * ln_wetland\n# - 0.236 * 0.6061358034 = -0.1430480496\n# ln_damages\n\n#calculate damage\ndamages &lt;- 18000000  \ndamage_new &lt;- damages * exp(ln_damages)\n#18,000,000 * exp(-0.1430480496)\n# damage_new\n\navoided_damage = damages - damage_new\n#18000000 - 15600824 = 2399176\navoided_damage #million\n\n\n[1] 2399176"
  },
  {
    "objectID": "portfolio/toh_restoration/index.html",
    "href": "portfolio/toh_restoration/index.html",
    "title": "Ailanthus altissima: Strategies for Control and Management in California",
    "section": "",
    "text": "Background:\nThe Tree of Heaven (Ailanthus altissima) is a fast-growing invasive species originally from China. Introduced as an ornamental plant, it has spread extensively beyond its native range, particularly throughout California. With prolific seed production and aggressive root suckering, A. altissima exhibits high reproductive capacity. Its allelopathic properties further enable it to outcompete and displace native plant communities (DiTomaso et al., 2013). This species thrives in a wide range of habitats but is especially common in disturbed areas, riparian zones, and foothills. Additionally, A. altissima demonstrates significant growth potential under warmer and drier conditions, suggesting it may expand further with climate change (Kn√ºsel et al., 2019; Motti et al., 2021).\n\n\n\nClockwise from left: Ailanthus altissima invasion (Joseph DiTomaso), Fruit (Bill Johnson), Foliage (Deborah Richardson)\n\n\n\n\nProblem:\nOnce A. altissima has been established in an area, it is difficult to remove and can alter ecosystem function. Herbicide application is often the most effective way to kill the root system, but successful eradication is not guaranteed, and repeated application is often necessary (DiTomaso et al., 2013). This can be costly. Therefore, it is crucial to understand the current and future distribution of A. altissima in California to prioritize areas for monitoring and removal.\n\n\nApproach:\nWe integrated 1,000 presence records of Ailanthus altissima with seven climate variables to develop a MaxEnt species distribution model using Wallace in R. Occurrence data was obtained from GBIF. Given A. altissima‚Äôs sensitivity to temperature and precipitation, we selected bioclimatic variables at a 5-arcminute resolution, including annual mean temperature, mean diurnal range, maximum temperature of the warmest month, minimum temperature of the coldest month, annual precipitation, precipitation of the wettest month, and precipitation of the driest quarter.\nTo improve processing efficiency, we restricted occurrence data to the United States and applied a 2.5-degree buffer around all occurrences to define the background extent‚Äîexcluding unsuitable areas (e.g., oceans) while capturing potentially suitable habitat based on the species‚Äô current distribution. Model validation was performed using 1,000 background points spatially partitioned into four blocks (k=4).\nSince our primary focus is A. altissima‚Äôs distribution in California, we projected the model onto a California-specific extent. To assess potential climate-driven range shifts, we also projected future distribution under the highest emissions scenario (SSP 585) for the 2041‚Äì2060 period.\n\n\nResults:\nFigures 1 and 2 suggest that Ailanthus altissima is likely to shift northeastward, with a new hotspot projected to emerge in the northeastern corner of California. Both current and future distribution models indicate a strong concentration of A. altissima in the Central Valley. Additionally, the species is predominantly found in and around urban centers, highlighting its preference for disturbed environments.\n\n\n\nFigure 1: Current Projected Ailanthus altissima Distribution in California. Species distribution was modeled using MaxEnt. A. altissima distribution was projected to be low (0.00384) in blue areas, moderate in yellow, and high (0.7859) in red areas. (Priscilla Ta)\n\n\n\n\n\nFigure 2: Future Projected Ailanthus altissima Distribution in California. Future A. altissima distribution was projected under SSP 585 over 2041-2060 in California using MaxEnt modeling. Areas of high (0.91) suitability are noted in red. Areas of low suitability (0.008) are blue. (Natalie Smith)\n\n\n\n\nConclusion:\nInvasive control efforts should prioritize urban areas where Ailanthus altissima threatens local habitats and ecosystem functionality. We recommend targeted removal in these regions, paired with the reintroduction of native vegetation to restore ecological balance. This strategy would not only curb the species‚Äô spread but also help mitigate urban climate challenges such as the heat island effect and stormwater runoff while enhancing biodiversity. Additionally, establishing an early detection and rapid response program in northeastern California would be crucial for preventing further expansion.\nFuture research should consider additional factors influencing A. altissima distribution, including road networks, land use patterns, and topography, to refine management strategies. Moreover, a balanced assessment of its ecological risks and potential benefits is needed to determine whether A. altissima could contribute to novel ecosystems in certain contexts (Sladonja et al., 2015). While the species may offer some advantages in highly altered environments, its aggressive spread requires careful regulation to prevent further ecological disruption.\n\n\nReferences:\nDiTomaso, J.M., Kyser, G.B., Oneto, S.R., Wilson, R.G., Orloff, S.B., Anderson, L.W., Wright, S.D., Roncoroni, J.A., Miller, T.L., Prather, T.S., Ransom, C., Beck, K.G., Duncan, C., Wilson, K.A., & Mann, J.J. (2013). Weed Control in Natural Areas in the Western United States. Weed Research and Information Center, University of California. 544 pp.\nKn√ºsel, S., Conedera, M., Zweifel, R., Bugmann, H., Etzold, S., & Wunder, J. (2019). High growth potential of Ailanthus altissima in warm and dry weather conditions in novel forests of southern Switzerland. Trees, 33(2), 395‚Äì409. https://doi.org/10.1007/s00468-018-1785-x\nMotti, R., Zotti, M., Bonanomi, G., Cozzolino, A., Stinca, A., & Migliozzi, A. (2021). Climatic and anthropogenic factors affect Ailanthus altissima invasion in a Mediterranean region. Plant Ecology, 222(12), 1347‚Äì1359. https://doi.org/10.1007/s11258-021-01183-9\nSladonja, B., Su≈°ek, M., & Guillermic, J. (2015). Review on invasive tree of heaven (ailanthus altissima (mill.) Swingle) conflicting values: Assessment of its ecosystem services and potential biological threat. Environmental Management, 56(4), 1009‚Äì1034. https://doi.org/10.1007/s00267-015-0546-5"
  },
  {
    "objectID": "portfolio/fish_passage/index.html",
    "href": "portfolio/fish_passage/index.html",
    "title": "Understanding Adult Fish Passage Dynamics at Willamette Falls",
    "section": "",
    "text": "In my analysis, I delved into the adult passage of Coho, Coho Jack, and Steelhead from 2001-2010 at the Willamette Falls fish ladder on the Willamette River (Oregon) using data from Columbia River DART (Data Access in Real Time). My focus was on identifying patterns and trends in fish passage based on time and season. Additionally, I aimed to determine the annual counts for each species. .\n\n\n\nAdult Male Coho Salmon, BLM"
  },
  {
    "objectID": "portfolio/fish_passage/index.html#attach-libraries",
    "href": "portfolio/fish_passage/index.html#attach-libraries",
    "title": "Understanding Adult Fish Passage Dynamics at Willamette Falls",
    "section": "Attach libraries:",
    "text": "Attach libraries:\n\n\nCode\nlibrary(tidyverse)\nlibrary(here)\nlibrary(tsibble)\nlibrary(feasts)\nlibrary(fable)\nlibrary(ggplot2)\nlibrary(tidyr)\nlibrary(viridis)\nlibrary(dplyr)"
  },
  {
    "objectID": "portfolio/fish_passage/index.html#import-and-wrangle-data",
    "href": "portfolio/fish_passage/index.html#import-and-wrangle-data",
    "title": "Understanding Adult Fish Passage Dynamics at Willamette Falls",
    "section": "Import and Wrangle Data:",
    "text": "Import and Wrangle Data:\nIn preparing the data, I transformed it into a time series format and converted the date column from character to date format. I then pivoted the data to consolidate fish species into a single column for streamlined analysis. Finally, any missing values were replaced with zeros to ensure data integrity.\n\n\nCode\n# Import Data\n\nwillamette_fish &lt;- read.csv(here(\"portfolio\",\"fish_passage\",\"willamette_fish_passage.csv\"))\n\n# Clean up data\nwf_clean &lt;- willamette_fish %&gt;%\n  janitor::clean_names() %&gt;% \n  mutate(date=lubridate::mdy(date)) %&gt;% \n  as_tsibble(key=NULL,index=date) %&gt;% \n  pivot_longer(!c(project,date),names_to = \"species\",values_to = \"number_of_salmon\") %&gt;% \n  filter(species %in% c(\"coho\",\"jack_coho\",\"steelhead\")) %&gt;% \n  replace_na(list(fish_ob=0))"
  },
  {
    "objectID": "portfolio/fish_passage/index.html#time-series-graph",
    "href": "portfolio/fish_passage/index.html#time-series-graph",
    "title": "Understanding Adult Fish Passage Dynamics at Willamette Falls",
    "section": "Time Series Graph:",
    "text": "Time Series Graph:\n\n\nCode\nggplot(wf_clean, aes(x = date, y = number_of_salmon, color = species)) +\n  geom_line() +\n  facet_wrap(~ species, scales = \"free_y\", ncol = 1, labeller = labeller(fish_species = c(\"coho\" = \"Coho\", \"jack_coho\" = \"Jack Coho\", \"steelhead\" = \"Steelhead\"))) +\n  labs(x = \"Date\", y = \"Count\") +\n  theme_minimal() +\n  scale_x_date(date_breaks = \"1 year\", date_labels = \"%Y\") +\n  scale_color_viridis_d(name = \"species\") +\n  theme(legend.position = \"none\")\n\n\n\n\n\n\n\n\nFigure¬†1: Time series analysis of adult passage for Coho, Jack Coho, and Steelhead Salmon from 2001 to 2010.\n\n\n\n\n\n\nMajor patterns and notable trends:\nCoho species exhibit a left-skewed pattern, with passage counts consistently increasing since 2009. Jack Coho species display a more uniform distribution, reaching peak passage counts in 2009. Steelhead demonstrate a consistent seasonal pattern throughout the analyzed time period."
  },
  {
    "objectID": "portfolio/fish_passage/index.html#monthly-and-weekly-seasonal-patterns",
    "href": "portfolio/fish_passage/index.html#monthly-and-weekly-seasonal-patterns",
    "title": "Understanding Adult Fish Passage Dynamics at Willamette Falls",
    "section": "Monthly and Weekly Seasonal Patterns:",
    "text": "Monthly and Weekly Seasonal Patterns:\n\n\nCode\nwf_season &lt;-wf_clean %&gt;% \n  group_by(species) %&gt;% \n  summarize(monthly_count=sum(number_of_salmon))   \n  \n wf_season %&gt;% gg_season(y=monthly_count, pal = viridis::viridis(8))+\n  facet_wrap(~ species, scales = \"free_y\", ncol = 1, \n             labeller = labeller(fish_species = c(\"coho\" = \"Coho\",\n                                                  \"jack_coho\" = \"Jack Coho\",\n                                                  \"steelhead\" = \"Steelhead\"))) +\n  labs(x='',y='Monthly Fish Passage')+\n  theme_minimal() +\n  scale_x_date(date_breaks = \"1 month\", date_labels = \"%b\")\n\n\n\n\n\n\n\n\nFigure¬†2: Total monthly returns of Salmon at Williamette River Dam. Lighter colors indicate later years with darker colors showing earlier years.\n\n\n\n\n\n\n\nCode\nwf_weekly &lt;- wf_clean %&gt;%\n  index_by(yr_mo=~yearweek(.)) %&gt;% \n  group_by(species) %&gt;% \n  summarize(monthly_count=sum(number_of_salmon))   \n  \nwf_weekly %&gt;% gg_season(y=monthly_count, pal = viridis::viridis(8))+\n  facet_wrap(~ species, scales = \"free_y\", ncol = 1, \n             labeller = labeller(fish_species = c(\"coho\" = \"Coho\",\n                                                  \"jack_coho\" = \"Jack Coho\",\n                                                  \"steelhead\" = \"Steelhead\"))) +\n    labs(x='',y='Weekly Fish Passage')+\n    theme_minimal()\n\n\n\n\n\n\n\n\nFigure¬†3: Total weekly returns of Salmon at Williamette River Dam. Lighter colors indicate later years with darker colors showing earlier years.\n\n\n\n\n\n\nKey Seasonal Trends:\n\nCoho and Jack Coho exhibit a similar seasonal pattern, peaking from September to November. Coho passage has increased in recent years, while Jack Coho passage has declined.\nSteelhead show a wider seasonal passage window, spanning from February to July, with a peak typically observed from May to July. The timing of peak passage varies across years.\nLate April and May mark the peak return period for Steelhead, although total returns during this period have declined over the years. This suggests a potential shift in the timing of returns, which is more evident when analyzing the data on a weekly basis."
  },
  {
    "objectID": "portfolio/fish_passage/index.html#approach",
    "href": "portfolio/fish_passage/index.html#approach",
    "title": "Understanding Adult Fish Passage Dynamics at Willamette Falls",
    "section": "Approach:",
    "text": "Approach:\nTo analyze annual counts for each species, I aggregated the data by year and fish species, calculating the total count for each year and species.\n\n\nCode\nsalmon_by_year &lt;- wf_clean%&gt;%\n  group_by(year = lubridate::year(date),species) %&gt;% \n  summarize(annual_count = sum(number_of_salmon)) %&gt;% \n  ungroup()\n\nyear_count &lt;- aggregate(annual_count ~ year + species, data = salmon_by_year, FUN = sum)\n\n\n\nAnnual Count Graph:\n\n\nCode\nannual_salmon_plot_line &lt;- year_count %&gt;%\n  ggplot(aes(x = year, y = annual_count, color = species)) +\n  geom_line() + \n  scale_color_viridis_d() + \n  labs(x = \"Year\",\n       y = \"Count\",\n       color = \"Species\") +\n  theme_minimal() +\n  scale_x_continuous(breaks = seq(min(salmon_by_year$year), max(salmon_by_year$year), by = 1)) +\n  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n\nannual_salmon_plot_line\n\n\n\n\n\n\n\n\nFigure¬†4: Annual totals of fish passage for Coho, Jack Coho, and Steelhead Salmon from 2000 to 2010.\n\n\n\n\n\n\n\nKey Trends in Annual Totals by Species (2000 - 2010):\n\nThe Coho species demonstrates a left-skewed distribution, with a consistent increase over the years, peaking in 2009, followed by a decline in 2010.\nJack Coho species displays a relatively uniform distribution, experiencing a gradual rise in species count from 2007, with a slight decline noted in 2010.\nDespite seasonal and annual increases and decreases, Steelhead populations are decreasing overall. The increase in 2009 may be a temporary improvement, but it‚Äôs crucial to analyze more recent data to determine if this is a consistent upward trend or a small fluctuation."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "While I began my career in music (Berklee College of Music), my passion for the environment and innate curiosity about natural systems led me to ecology. After working on restoration projects with the Audubon Center and TreePeople, I deepened my expertise with a Horticulture Certification (UCLA) and a California Native Plant Landscaper Certificate.\nSince then, I spearheaded the Native Plant Program at Fig Earth Supply, then moved into environmental consulting‚Äîsupporting ecological assessments, restoration projects, and stakeholder engagement with organizations like AECOM, Great Ecology, and LegacyWorks Group. I‚Äôm now pursuing my Master‚Äôs at the Bren School of Environmental Science & Management (UCSB), focusing on conservation planning and climate adaptation.\nIn my free time, you can find me tending to my garden, at the movies, or listening to old records with a good cup of coffee.\n\n\n\n\nEducationCertificationsConferences\n\n\nMaster of Environmental Science and Management | 2025 | Bren School Of Environmental Science & Management at UCSB\nBachelor of Music | Berklee College of Music\n\n\nLeed Green Associate | 2023\nWildfire Defense Professional (USGBC-LA) | 2022\nCalifornia Native Plant Landscaper Certificate (CNPLC) | 2021\nHorticulture (UCLA Extension) | 2020\n\n\nNational Adaptation Forum | 2024\nCalifornia Native Plant Society Conference | 2021"
  },
  {
    "objectID": "music.html",
    "href": "music.html",
    "title": "Music",
    "section": "",
    "text": "Natalie + Eric = Cape Weather\n\n\n\n\nBefore shifting into environmental work, I spent over five years as a professional musician‚Äîwriting, performing, and teaching to diverse audiences. As part of the band Cape Weather, I‚Äôve released 6+ EPs, including the critically acclaimed single Telephono, earning over 3 million Spotify streams and placements in film and TV. Our music has been featured on NPR and KCRW, and I collaborated on visually striking music videos to bring our songs to life. Beyond Cape Weather, I‚Äôve performed at 100+ corporate and private events and provided background vocals for artists like Ben Folds.\nüé∂ Click the photos below to listen!"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Natalie Smith",
    "section": "",
    "text": "Hi, I‚Äôm Natalie.\nI‚Äôm a scientist, communicator, musician, and crafter ‚Äì usually daydreaming about climate solutions, native plants, and ways to make the world a little greener. \nI‚Äôve compiled some of my recent work here. Feel free to explore and get in touch!"
  },
  {
    "objectID": "index.html#about-me",
    "href": "index.html#about-me",
    "title": "Natalie Smith",
    "section": "",
    "text": "Hi, I‚Äôm Natalie.\nI‚Äôm a scientist, communicator, musician, and crafter ‚Äì usually daydreaming about climate solutions, native plants, and ways to make the world a little greener. \nI‚Äôve compiled some of my recent work here. Feel free to explore and get in touch!"
  },
  {
    "objectID": "index.html#project-highlights",
    "href": "index.html#project-highlights",
    "title": "Natalie Smith",
    "section": "Project Highlights",
    "text": "Project Highlights\nEvaluating Ecological Conservation Gaps Across a Proposed Sentinel Landscape (Connectivity)\nWildlife Connectivity Across The Central California Coast\nMapping Heat-Risk Inequalities in Los Angeles County"
  },
  {
    "objectID": "index.html#professional-interests",
    "href": "index.html#professional-interests",
    "title": "Natalie Smith",
    "section": "Professional Interests",
    "text": "Professional Interests\nClimate Adaptation | Urban Biodiversity | Connectivity | Environmental Justice | Nature Based Solutions | Sustainability | Built Ecology | California Native Plants"
  },
  {
    "objectID": "index.html#skill-sets",
    "href": "index.html#skill-sets",
    "title": "Natalie Smith",
    "section": "Skill Sets",
    "text": "Skill Sets\nEcology | Data Science | GIS | R Programming Language | Excel | Project Management | Stakeholder Engagement"
  },
  {
    "objectID": "portfolio/pca/index.html",
    "href": "portfolio/pca/index.html",
    "title": "Analyzing Socioeconomic and Environmental Factors in LA",
    "section": "",
    "text": "Between 1935 and 1940, the HOLC created color-coded maps evaluating neighborhoods‚Äô mortgage security based on criteria such as housing quality, property values, and residents‚Äô racial and ethnic backgrounds. The maps categorized areas into four types: ‚ÄúType A‚Äù (green) neighborhoods were the most desirable, ‚ÄúType B‚Äù (blue) were still desirable, ‚ÄúType C‚Äù (yellow) were declining, and ‚ÄúType D‚Äù (red) were the riskiest, often older districts in city centers and predominantly Black.\nFor this assignment, we examined correlations between Census data, Tree Canopy Coverage, Heat Risk, and Redlining Grades in Los Angeles, CA. Utilizing the data that was previously wrangled for our ‚ÄúMapping Heat Risk Inequality‚Äù Shiny app (Natalie Smith and Olivia Hemond), we delved into these relationships for analysis.\n\n\n\nLos Angeles, RDNE Photo Archive"
  },
  {
    "objectID": "portfolio/pca/index.html#footnotes",
    "href": "portfolio/pca/index.html#footnotes",
    "title": "Analyzing Socioeconomic and Environmental Factors in LA",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFull list of Principal Components Analysis (PCA) variables:\n\nAsthma: Age-adjusted rate of emergency department visits for asthma\nDiesel PM (diesel_pm): Emissions from on-road and non-road sources\nDrinking Water: Drinking water contaminant index for selected contaminants\nEducation: Percent of population over 25 with less than a high school education\nExisting Canopy Coverage (existing_canopy_pct): Percent of existing canopy coverage\nHeat Risk: Daily excess number of emergency visits during an extreme heat day\nLead: Potential risk for lead exposure in children living in low-income communities with older housing\nLinguistic Isolation (ling_isol): Percent limited English speaking households\nPM 2.5 (pm2_5): Annual mean PM2.5 concentrations\nPoverty: Percent of population living below two times the federal poverty level\nTraffic: Traffic density in vehicle-kilometers per hour per road length, within 150 meters of the census tract boundary\nUnemployment: Percent of the population over the age of 16 that is unemployed and eligible for the labor force\n\n‚Ü©Ô∏é"
  },
  {
    "objectID": "portfolio/gis_air_nyc/index.html",
    "href": "portfolio/gis_air_nyc/index.html",
    "title": "Air,NYC: Mapping the Concrete Jungle",
    "section": "",
    "text": "Background:\nDenser urban populations encounter elevated levels of air pollution resulting from intensified traffic, construction, and human activity, affecting public health, the environment, economy, climate, and overall welfare. This summary is a component of the final project presentation for my master‚Äôs course ESM 263: GIS.\n\n\n\nThe view to the south from the Empire State Building on Nov.¬†24, 1966, one of New York‚Äôs worst smog days. Credit: Neal Boenzi/The New York Times\n\n\nCommon Contaminants:\n\nPM 2.5: Originates from diesel engines, biomass burning, industrial processes, and residential heating; poses health risks due to fine particles penetrating deep into lungs.\nBlack Carbon: Emitted from diesel engines and biomass burning; absorbs sunlight, causing localized warming effects.\nNitrogen dioxide (NO2) & Nitric Oxide (NO): Combustion byproducts from vehicles and industries; contribute to smog, acid rain, and respiratory issues.\n\n\n\nProject Goals\nThe goal of this project was to comprehensively assess the air quality in New York City using GIS. Specifically we:\n\nQuantified air quality\nAnalyzed the average air quality in different areas\nCompared the mean air qualities to better understand causes of air pollution\n\n\n\nData Sources:\n\nNew York City Community Air Survey: Air Pollution Rasters 2021\n\nPM 2.5\nBlack Carbon\nNitrogen dioxide (NO2) and Nitric Oxide (NO)\n\nNYC Department of City Planning (DCP), Borough Boundaries (Polygon)\nNYC Department of City Planning (DCP), Zoning Features (Polygon)\nNYC Department of City Planning (DCP), Census Tracts 2020 (Polygon)\n\n\n\n\nSurvey team member deploys a monitor in the field\n\n\nWe utilized a variety of open-source raster and vector data sources, including the NYC Department of City‚Äôs Planning Borough, Zoning, and Census data, as well as the New York Community Air Survey Data. This air pollution survey data offers insights into citywide air pollution levels, with samples collected seasonally for two weeks, focusing on six contaminants. Monitor locations were strategically chosen to encompass diverse neighborhood characteristics and potential emission sources, including 15 environmental justice sites in low-income areas. For out analysis, we focused on the pollutants with annual averages: NO, NO2, PM2.5, and BC.\n\n\nConceptual Model and Methods:\nWe took the following steps in our analysis:\n\nStarted with four air quality rasters, census tract data, and zoning data\nIdentified zoning types corresponding to industry in NYC and selectively utilized this data through attribute selection.\nReprojected all data to WGS 1984 Zone 18N and converted two polygons to rasters\nResampled our data to 30m for more granularity\nReclassified the data into three quantiles, with the original intention of using EPA recommendations but faced challenges in obtaining relevant data.\nCombined the rasters using raster calculator to provide an overview of general air quality across the city, categorized into low, medium, and high levels.\nConducted zonal statistics (majority) with both census and industrial data, followed by zonal statistics by table to obtain specific values for each tract and industrial zone.\nJoined these values back to the original polygons.\nEmployed summary statistics to determine the mean value for all census tracts and industrial districts.\nSymbolized the data based on values from the raster calculator and zonal statistics, categorized into low, medium, and high air quality levels for ease of interpretation.\n\n\n\nNYC Air Quality, Census Tracts:\nThere are relative disparities in air quality across all boroughs based on census data. Values obtained from our model ranged from 4 to 12, which were subsequently categorized into three groups: low, medium, and high. These categories were symbolized on the map for visualization, with darker colors indicating higher pollution. Additionally, a mean value of 9.72 was calculated to facilitate comparison with our industrial districts.\nAdditional analysis conducted by my colleague, Sam Lance, on industrial districts confirms our findings. Industrial areas show similar air quality trends to census tracts, with the most severe pollution centered around Manhattan and neighboring parts of Brooklyn and Queens. The majority mean air quality index in industrial zones is 10.91, surpassing the average for census tracts, highlighting the need for further investigation into industrial emissions‚Äô impact on air quality.\n\n\nReferences:\n\nData Sources:\nNew York City Community Air Survey: Air Pollution Rasters 2020\nPM 2.5, Black Carbon, Nitrogen dioxide (NO2) and Nitric Oxide (NO), Sulfur dioxide (SO2)\nNYC Department of City Planning (DCP), Borough Boundaries (Polygon)\nNYC Department of City Planning (DCP), Zoning Features (Polygon)\nNYC Department of City Planning (DCP), Census Tracts 2020 (Polygon)\n\n\nStudies:\nNew York City Community Air Survey. NYC Community Air Survey - NYC Health. http://tiny.cc/NYCSurvey\nEnvironmental Protection Agency. EPA. https://tinyurl.com/aqi2021"
  },
  {
    "objectID": "portfolio/green_investing/index.html",
    "href": "portfolio/green_investing/index.html",
    "title": "Tradeoffs of Green Investing",
    "section": "",
    "text": "This is an excerpt from a larger report examining the trade-offs of investing in green companies and divesting from brown companies, developed for a Cost-Benefit Analysis course."
  },
  {
    "objectID": "portfolio/green_investing/index.html#data-sources-and-timeframe",
    "href": "portfolio/green_investing/index.html#data-sources-and-timeframe",
    "title": "Tradeoffs of Green Investing",
    "section": "Data Sources and Timeframe",
    "text": "Data Sources and Timeframe\nHistorical adjusted closing prices (ACP) for each company in the portfolio were sourced from Yahoo Finance. ACP, which adjusts for corporate actions such as dividends and stock splits, provides a more accurate measure of stock value over time. A five-year timeframe (2018‚Äì2023) was selected to balance historical stock performance with available greenhouse gas (GHG) emissions data, creating a solid foundation for our analysis.\n\n\nCode\n# Load libraries\nlibrary(tidyverse)\nlibrary(quantmod)\nlibrary(dplyr)\n\n\n\n\nCode\n# Set parameters\n\n#define the date range\nstart_date &lt;- \"2018-01-01\"\nend_date &lt;- \"2023-12-31\"\n\n# Define company tickers\ntickers &lt;- c(\"XOM\", \"CVX\", \"BP\", \"COP\", \"SHEL\", \"NEE\", \"IBDRY\", \"ENPH\", \"BEP\", \"FSLR\")\n\n# Define carbon intensities for each company (in tonnes of CO2 per unit of revenue)\nemissions_intensity  &lt;- c(\n  XOM = 0.002,     # Exxon Mobil\n  CVX = 0.008,    # Chevron\n  BP = 0.002,     # BP\n  COP = 0.004,    # ConocoPhillips\n  SHEL = 0.004,    # Shell\n  NEE = 0.002,     # NextEra Energy\n  IBDRY = 0.001,    \n  ENPH = 0.00003,  # Enphase Energy\n  BEP = 0.000005,  # Brookfield Renewable Partners\n  FSLR = 0.0013    # First Solar\n)\n\n# Social Cost of Carbon (SCC) in dollars per tonne of CO2\nSCC &lt;- 185"
  },
  {
    "objectID": "portfolio/green_investing/index.html#financial-analysis",
    "href": "portfolio/green_investing/index.html#financial-analysis",
    "title": "Tradeoffs of Green Investing",
    "section": "Financial Analysis",
    "text": "Financial Analysis\nAll stock data were compiled into a single data frame in RStudio (see Appendix A for full code). Daily returns were calculated to assess day-to-day performance. These returns, representing the percentage change in ACP from one day to the next, were generated using the ROC() function with type = ‚Äúdiscrete,‚Äù ensuring returns were calculated using the formula:\n\\[\n\\text{Return} = \\frac{P_t - P_{t-1}}{P_{t-1}} = \\frac{P_t}{P_{t-1}} - 1\n\\]\nWhere Pt is the current adjusted close price, and Pt-1 is the previous day‚Äôs adjusted close price. Mean daily returns were annualized by multiplying by 252, the typical number of trading days per year. Volatility, the rate at which the price of a stock fluctuates over time, was then calculated as the standard deviation of annual returns. The result was divided by the square root of 12 to convert this to a monthly measure.\n\n\nCode\n#get data to build portfolios\n#getSymbols = fetches historical stock data for these tickers from Yahoo Finance\n\nfor (ticker in tickers) {\n  getSymbols(ticker, src = \"yahoo\", from = start_date, to = end_date)\n}\n\n# Merge adjusted closing prices for all tickers into a single data frame.\nprices &lt;- do.call(merge, lapply(tickers, function(ticker) Ad(get(ticker))))\n\n# Calculate daily returns for each stock \nreturns &lt;- na.omit(ROC(prices, type = \"discrete\"))\n\n# Calculate annualized average return.\navg_return &lt;- mean(returns) * 252\n\n# Calculate monthly volatility (standard deviation of returns).\nsd_og &lt;- sd(returns)\nsd &lt;- sd_og / sqrt(12)"
  },
  {
    "objectID": "portfolio/green_investing/index.html#simulation-of-portfolio-performance",
    "href": "portfolio/green_investing/index.html#simulation-of-portfolio-performance",
    "title": "Tradeoffs of Green Investing",
    "section": "Simulation of Portfolio Performance",
    "text": "Simulation of Portfolio Performance\nA Monte Carlo simulation was conducted to model financial and environmental outcomes across 100 randomized scenarios over a 5-year period (60 months). The simulation begins with an initial investment of $10,000, which was randomly allocated across a portfolio of 10 companies. These allocations were normalized to ensure they summed to 1, ensuring proportional distribution across the portfolio. Monthly returns for each company were generated using a normal distribution based on historical average returns. To reflect monthly values, the mean return was divided by 12, and the standard deviation was adjusted by the square root of 12. Portfolio performance was tracked throughout the simulation by applying monthly portfolio returns, calculated as the weighted sum of company-level returns based on their allocation to the portfolio‚Äôs value. Individual company portfolio values were also tracked to assess their contributions to the overall portfolio performance. At the end of each simulation, the cumulative return was determined as the percentage change in the portfolio‚Äôs value relative to the initial investment, representing total gain or loss over the 5-year period.\nEmissions were calculated for each company by multiplying its allocated portion of the initial investment by its emissions intensity, measured as CO2emission per unit of revenue. These emissions were then multiplied by the Social Cost of Carbon (SCC). The total environmental cost for each scenario was obtained by summing the costs across all companies in the portfolio.\nVolatility was calculated at both the company and portfolio levels throughout the simulation. Company-level volatility was determined by annualizing the standard deviation of monthly returns, while portfolio volatility represented the overall risk, combining all companies‚Äô performance. After completing all 100 scenarios, results were aggregated to analyze trends in financial returns, environmental costs, and volatility, providing insights into the trade-offs between financial and environmental metrics for green and brown firms.\n\n\nCode\n#set up initial variables\nset.seed(123)  #for reproducibility\ninitial_investment &lt;- 10000 # starting investment is 10k\nn_scenarios &lt;- 100  #number of scenarios to simulate\nn_months &lt;- 60  #simulation for 5 years (60 months)\n\n# Initialize results list to store each scenario's data before combining\nresults_list &lt;- vector(\"list\", n_scenarios)\n\n\n\n\nCode\n# Run scenarios to simulate random allocation\nfor (i in 1:n_scenarios) {\n  # Random allocation for each company\n  allocation &lt;- runif(length(tickers))\n  allocation &lt;- allocation / sum(allocation)  # Normalize to sum to 1\n  \n  # Generate monthly returns for each company\n  company_monthly_returns &lt;- matrix(rnorm(n_months * length(tickers), avg_return / 12, sd / sqrt(12)),\n                                    nrow = n_months, ncol = length(tickers))\n  \n  # Initialize portfolio value and returns\n  portfolio_value &lt;- initial_investment\n  monthly_portfolio_returns &lt;- numeric(n_months)\n  \n  # Initialize matrix and vectors\n  company_final_returns &lt;- numeric(length(tickers))\n  company_portfolio_values &lt;- matrix(0, nrow = n_months, ncol = length(tickers))\n  emissions &lt;- initial_investment * allocation * emissions_intensity\n  environmental_cost_allocation &lt;- emissions * SCC\n  \n  # Update portfolio value based on monthly returns and allocation\n  for (j in 1:n_months) {\n    company_returns_at_j &lt;- company_monthly_returns[j, ]  # Returns for all companies at month j\n    \n    # Update portfolio and monthly return\n    portfolio_monthly_return &lt;- sum(company_returns_at_j * allocation)\n    portfolio_value &lt;- portfolio_value * (1 + portfolio_monthly_return)\n    monthly_portfolio_returns[j] &lt;- portfolio_monthly_return\n    \n    # Calculate individual company portfolio values\n    for (k in 1:length(tickers)) {\n      if (j == 1) {\n        company_portfolio_values[j, k] &lt;- initial_investment * allocation[k] * (1 + company_returns_at_j[k])\n      } else {\n        company_portfolio_values[j, k] &lt;- company_portfolio_values[j - 1, k] * (1 + company_returns_at_j[k])\n      }\n    }\n    \n    # Accumulate final returns\n    company_final_returns &lt;- company_final_returns + company_returns_at_j * allocation\n  }\n  \n  # Final calculations outside the monthly loop\n  total_return &lt;- (portfolio_value - initial_investment) / initial_investment\n  total_enviro_cost_scenario &lt;- sum(environmental_cost_allocation)\n  company_final_portfolio_values &lt;- company_portfolio_values[n_months, ]\n  \n  # Calculate volatilities\n  company_volatilities &lt;- apply(company_monthly_returns, 2, sd) * sqrt(12)  # Annualize\n  portfolio_volatility &lt;- sd(monthly_portfolio_returns) * sqrt(12)\n  \n  # Store results\n  results_list[[i]] &lt;- data.frame(\n    scenario = i,\n    company = tickers,\n    allocation = allocation,\n    final_portfolio_value = portfolio_value,\n    total_return = total_return,\n    company_final_return = company_final_returns,\n    company_final_portfolio_value = company_final_portfolio_values,\n    emissions = emissions,\n    environmental_cost_allocation = environmental_cost_allocation,\n    total_enviro_cost_scenario = total_enviro_cost_scenario,\n    company_volatility = company_volatilities,\n    scenario_volatility = portfolio_volatility\n  )\n}\n\n# Combine all results\nresults &lt;- do.call(rbind, results_list)"
  },
  {
    "objectID": "portfolio/green_investing/index.html#financial-performance",
    "href": "portfolio/green_investing/index.html#financial-performance",
    "title": "Tradeoffs of Green Investing",
    "section": "Financial Performance",
    "text": "Financial Performance\nThe companies exhibited relatively similar returns, with First Solar (FSLR) achieving the highest mean return at 13.02%, closely followed by Enphase (ENPH) and Iberdrola (IBDRY) at 12.57% and 12.52%, respectively. These results reflect positive growth for all companies, with portfolio values reaching between $3,094 and $3,551 (Figure 2), suggesting a moderate increase in value across the board. Notably, green firms, such as FSLR, ENPH, and IBDRY, displayed slightly higher returns compared to their Brown counterparts, with average portfolio growth ranging from $3,217 to $3,551.\n\n\nCode\nportfolio_value_plot &lt;- ggplot(company_summary, aes(x = reorder(company, mean_company_final_portfolio_value), y = mean_company_final_portfolio_value, fill = firm_type)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = c(\"Green\" = \"seagreen\", \"Brown\" = \"peachpuff4\")) +\n  labs(title = \"Company Portfolio Growth\",\n       subtitle = \"Mean Across 100 Scenarios Over 5 Years\",\n       x = \"Company\", y = \"Mean Portfolio Growth ($)\", fill = \"Firm Type\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\nportfolio_value_plot\n\n\n\n\n\nFigure 2. Mean Portfolio Growth Across 100 Scenarios Over 5 Years for Each Company. The average final portfolio value for each company, categorized as Green or Brown based on their portfolio growth. Green companies generally show higher portfolio growth compared to Brown companies. The companies listed by abbreviation in the plot are as follows: FSLR (First Solar), ENPH (Enphase Energy), IBDRY (Iberdrola), BP (British Petroleum), SHEL (Shell), CVX (Chevron), NEE (NextEra Energy), XOM (ExxonMobil), BEP (Brookfield Renewable Partners), and COP (ConocoPhillips)."
  },
  {
    "objectID": "portfolio/green_investing/index.html#environmental-costs",
    "href": "portfolio/green_investing/index.html#environmental-costs",
    "title": "Tradeoffs of Green Investing",
    "section": "Environmental Costs",
    "text": "Environmental Costs\nEnvironmental costs showed a significant variation across the companies (Figure 3). The Green firms generally had lower environmental costs over the 5-year scenario, with the exception of NextEra Energy (NEE), which had a moderate environmental cost of $368.99. In contrast, the Brown firms, particularly Chevron (CVX) and Shell (SHEL), exhibited higher environmental costs, with CVX reaching $1,492.10 and SHEL at $750.26. BP and COP also demonstrated notable environmental costs, highlighting the greater ecological impact associated with these companies.\n\n\nCode\n# Plot Mean Environmental Cost\nenvironmental_plot &lt;- ggplot(company_summary, aes(x = reorder(company, mean_enviro_cost), \n                                                  y = mean_enviro_cost, fill = firm_type)) +\n  geom_bar(stat = \"identity\") +\n  scale_fill_manual(values = c(\"Green\" = \"seagreen\", \"Brown\" = \"peachpuff4\")) +\n  labs(title = \"Mean Environmental Cost Per Company\", \n       subtitle = \"Mean Across 100 Scenarios Over 5 Years\",\n       x = \"Company\", y = \"Mean Environmental Cost ($)\", fill = \"Firm Type\") +\n  theme_minimal() +\n  theme(axis.text.x = element_text(angle = 90, hjust = 1))\n\n\n# Display the plot\nenvironmental_plot\n\n\n\n\n\nFFigure 3. Mean Environmental Cost Across 100 Scenarios Over 5 Years for Each Company. The average environmental cost for each company, categorized as Green or Brown based on their environmental impact. Green companies generally have lower environmental costs compared to Brown companies. The companies listed by abbreviation in the plot are as follows: FSLR (First Solar), ENPH (Enphase Energy), IBDRY (Iberdrola), BP (British Petroleum), SHEL (Shell), CVX (Chevron), NEE (NextEra Energy), XOM (ExxonMobil), BEP (Brookfield Renewable Partners), and COP (ConocoPhillips)."
  },
  {
    "objectID": "portfolio/green_investing/index.html#volatility",
    "href": "portfolio/green_investing/index.html#volatility",
    "title": "Tradeoffs of Green Investing",
    "section": "Volatility",
    "text": "Volatility\nVolatility across the companies was relatively consistent, with values ranging from 0.00747 to 0.00765. No significant differences were observed between green and brown firms, suggesting that market risk remained fairly stable across both categories."
  },
  {
    "objectID": "portfolio/pm2_5_la/index.html",
    "href": "portfolio/pm2_5_la/index.html",
    "title": "Tracking PM2.5 Trends in Los Angeles",
    "section": "",
    "text": "As a long-time Angeleno, I‚Äôm no stranger to hazy days and pollution soaked sunsets, but this past December felt different. The air was thick, smothering the city in a gray blanket that lingered for weeks. I found myself wondering‚Äîwas the pollution actually worse, or was I simply more aware of it this time? Curious about whether this perception was backed by data, I decided to take a deeper dive into the air quality trends in Los Angeles."
  },
  {
    "objectID": "portfolio/pm2_5_la/index.html#finding-inspiration",
    "href": "portfolio/pm2_5_la/index.html#finding-inspiration",
    "title": "Tracking PM2.5 Trends in Los Angeles",
    "section": "3.1 Finding Inspiration",
    "text": "3.1 Finding Inspiration\nI began by gathering inspiration and experimenting with various plot styles. A photo of a smoggy LA skyline inspired my color choices. I used a color grabber tool to extract a palette from the image, then adjusted it for accessibility to ensure it was readable for all viewers. For typography, I selected Montserrat and Open Sans, which offer a balance of professionalism and readability without detracting from the visuals. For more about the general design and design elements jump to the ‚Äòdesign elements‚Äô section.\n\n\n\nCreating a vision board in Affinitiy Designer for the infographic using an LA skyline photo. The color palette was extracted from the image, with typography options laid out alongside."
  },
  {
    "objectID": "portfolio/pm2_5_la/index.html#r-setup-data-and-wrangling",
    "href": "portfolio/pm2_5_la/index.html#r-setup-data-and-wrangling",
    "title": "Tracking PM2.5 Trends in Los Angeles",
    "section": "3.2 R Setup, Data, and Wrangling",
    "text": "3.2 R Setup, Data, and Wrangling\nIn the next phase of the project, I set up my environment in R Studio by loading the necessary libraries, setting up my color palette, importing custom fonts, and loading the data from CalEnviroscreen and the EPA. A significant amount of data wrangling was required for each visualization, and throughout this blog post, you can click and expand the code chunks to view more details about the process. Links to the data sources and the specific code used for wrangling will be provided in the following sections.\n\n\nCode\n# The following R code sets up the environment by importing necessary libraries, cleaning data, and defining custom colors for the map visualization.\n\n#libraries: \nlibrary(tidyverse)   \nlibrary(janitor)     \nlibrary(lubridate)\nlibrary(here)        \nlibrary(doBy)      \nlibrary(scales)\nlibrary(showtext) \nlibrary(glue)\nlibrary(ggtext)\nlibrary(sf)\nlibrary(here)\n\n#......................import Google fonts.......................\n# `name` is the name of the font as it appears in Google Fonts\n# `family` is the user-specified id that you'll use to apply a font in your ggpplot\nfont_add_google(name = \"Montserrat\", family = \"mont\")\nfont_add_google(name = \"Open Sans\", family = \"open_sans\")\n\n\n\n# turn show text on\nshowtext_auto()\n\n# option 1\nsmog_pal &lt;- c(\"#79AAB6\", \n              \"#B0C7C1\", \n              \"#E3AC79\", \n              \"#CC7E62\",\n              \"#B77B70\")\n\n\n# option 2\nsmog_pal2 &lt;- c(\"#79AAB6\", \n              \"#B0C7C1\", \n              \"#DFAF75\", \n              \"#DE8635\",\n              \"#DF674F\")\n\n\n# option 3\nsmog_sub_pal &lt;- smog_pal2[c(4,5)]"
  },
  {
    "objectID": "portfolio/pm2_5_la/index.html#mapping-pm-2.5-in-los-angeles",
    "href": "portfolio/pm2_5_la/index.html#mapping-pm-2.5-in-los-angeles",
    "title": "Tracking PM2.5 Trends in Los Angeles",
    "section": "3.3 Mapping PM 2.5 in Los Angeles",
    "text": "3.3 Mapping PM 2.5 in Los Angeles\nTo answer where is PM2.5 distribution across Los Angeles, I used CalEnviroScreen (2023) data, mapping percentiles at the census tract level. Percentiles rank each tract‚Äôs pollution concentration relative to all others in California, helping identify high-exposure areas. The analysis also revealed that areas with high PM2.5 pollution often overlap with neighborhoods facing significant poverty, highlighting the intersection of environmental and socioeconomic disparities.\n\n\nCode\n #| eval: true\n #| echo: false\n #| message: false\n #| warning: false\n\n# bring in enviroscreen shapefile\n    enviroscreen_sf &lt;- read_sf(here(\"portfolio/pm2_5_la/data/enviroscreen_shapefiles/CES4_final_shapefile.shp\")) %&gt;% \n      clean_names() \n\n\n#-------- Tidy Data-------------\n\n# Define excluded locations\n    excluded_locations &lt;- c(\"Santa Clarita\", \"Palmdale\", \"Lancaster\", \"Acton\", \n                           \"Agua Dulce\", \"Altadena\", \"Lake Los Angeles\",\n                           \"Leona Valley\", \"La Crescenta-Montrose\")\n\n    excluded_tracts &lt;- c(\"6037911001\", \"6037910002\", \"6037403325\", \"6037104124\",\n                         \"6037920326\", \"6037930301\", \"6037910709\", \"6037920303\")\n\n    excluded_zips &lt;- c(\"90265\", \"93535\", \"93552\", \"93532\", \"90704\",\n                       \"91384\", \"91387\", \"91390\", \"93510\", \"93536\", \"91351\",\n                       \"91011\", \"91355\", \"93551\", \"91342\", \"91381\")\n\n\n# Tidy data \n    enviroscreen_sf &lt;- enviroscreen_sf %&gt;% \n      filter(county == \"Los Angeles\") %&gt;% \n      select(tract, \n             zip,\n             approx_loc,\n             pm2_5_p,\n             geometry,  \n             county) %&gt;% \n      filter(!approx_loc %in% excluded_locations) %&gt;%\n      filter(!tract %in% excluded_tracts) %&gt;%\n      filter(!zip %in% excluded_zips)\n\n\n\n\n\n\n\nFigure 1: Spatial distribution of PM2.5 pollution in Los Angeles. Census tracts are shaded based on their PM2.5 percentiles relative to all of California, with darker shades indicating higher pollution levels. Even neighborhoods with lower pollution still experience 50% more pollution compared to the rest of California. Areas in the 90th percentile include Reseda, Van Nuys, and Central Los Angeles."
  },
  {
    "objectID": "portfolio/pm2_5_la/index.html#identifying-pollution-sources",
    "href": "portfolio/pm2_5_la/index.html#identifying-pollution-sources",
    "title": "Tracking PM2.5 Trends in Los Angeles",
    "section": "3.4 Identifying Pollution Sources",
    "text": "3.4 Identifying Pollution Sources\nTo answer the question of major sources of PM2.5, I analyzed the EPA‚Äôs 2020 National Emissions Inventory (NEI), which tracks air pollution from both point and nonpoint sources. Point sources are single, identifiable emitters like power plants and factories, while nonpoint sources are more diffuse, stemming from widespread activities such as residential heating and vehicle emissions.\nI combined these datasets and categorized them by source type, ranking the top emitters by total emissions. The final visualization used a horizontal bar chart to compare pollution sources, with an annotation marking the 100-ton threshold for major contributors. I explored putting the tons emitted at the end of each bar to eliminate the need for the y-axis, but I didn‚Äôt like the data-to-ink ratio.\n\n\n\n\n\nFigure 2: Top 10 sources of PM2.5 pollution in Los Angeles in 2020, categorized into point and non-point sources. Point sources refer to specific, stationary facilities such as petroleum refineries, while non-point sources are more diffuse and widespread, including Industrial Processes, Residential Wood Combustion, and Light Duty Vehicles. The dashed horizontal line indicates the EPA‚Äôs threshold for major sources, defined as those emitting more than 100 tons of PM2.5 annually."
  },
  {
    "objectID": "portfolio/pm2_5_la/index.html#visualizing-pollution-over-time",
    "href": "portfolio/pm2_5_la/index.html#visualizing-pollution-over-time",
    "title": "Tracking PM2.5 Trends in Los Angeles",
    "section": "3.5 Visualizing Pollution Over Time",
    "text": "3.5 Visualizing Pollution Over Time\nMy final visualization aimed to answer how PM2.5 levels have changed over time. I analyzed the EPA‚Äôs Outdoor Air Quality dataset, calculating annual mean concentrations from 2010 onward. The resulting line plot showed trends over the past decade, with black points representing yearly averages and a red point emphasizing a 2020 spike caused by the Bobcat Fire. To draw attention to this anomaly, I added an annotation and an arrow pointing to the data point.\n\n\n\n\n\nFigure 3: Trends in PM2.5 levels in Los Angeles from 2010 to 2024, showing a consistent decline in pollution, although levels remain above the 9 ¬µg/m¬≥ threshold, placing LA in the moderate pollution category. As noted by a red point, there is a spike in PM 2.5 in 2020, presumably due to the Bobcat Fire."
  },
  {
    "objectID": "portfolio/pm2_5_la/index.html#putting-it-all-together-in-affinity-designer",
    "href": "portfolio/pm2_5_la/index.html#putting-it-all-together-in-affinity-designer",
    "title": "Tracking PM2.5 Trends in Los Angeles",
    "section": "3.6 Putting it All Together in Affinity Designer",
    "text": "3.6 Putting it All Together in Affinity Designer\nAfter generating all my visualizations, I exported them from R as PDFs and imported them into Affinity Designer. As a vector-based tool, Affinity allowed for precise adjustments to the size, colors, and intricate details of the graphics. I replaced graph titles, subtitles, and legends with annotations to streamline the final look and improve the data-to-ink ratio. Additionally, I included a hand-drawn illustration comparing PM2.5 particles to the width of a human hair, to give context and scale to the size of these pollutants."
  },
  {
    "objectID": "portfolio/pm2_5_la/index.html#design-elements",
    "href": "portfolio/pm2_5_la/index.html#design-elements",
    "title": "Tracking PM2.5 Trends in Los Angeles",
    "section": "3.7 Design Elements",
    "text": "3.7 Design Elements\nWhen creating an infographic, it‚Äôs important to carefully consider various design elements. My goal was for the visualizations to connect and convey a cohesive story. In this section, I‚Äôll walk you through my thought process and the reasoning behind my choices for the design elements listed below.\n\nGraphic FormTextThemesColorsTypographyGeneral DesignContextMessageAccessibilityDEI\n\n\nWhile I experimented with several plot types, I ultimately chose a choropleth map, a bar graph, and a line plot. My goal was to use a variety of shapes to convey dynamic movement between the plots, effectively telling the story of the pollutant. I also experimented with displaying the overall AQI and all the pollutants in the AQI as bubbles, but this approach took attention away from the central focus on PM2.5 pollution in Los Angeles.\n\n\nTo create consistency across my visualizations, you‚Äôll notice that each one includes titles, subtitles, and captions. I also minimized the use of axis titles where they weren‚Äôt absolutely necessary. In the final infographic, I moved away from traditional titles and subtitles, opting instead for annotations and colors to provide context and guide the reader through the story. Additionally, I used annotations in both the standalone graphs and the final infographic to emphasize key points, such as the 100-ton threshold for major pollution sources in the bar graph.\n\n\nMy general aesthetic preference is quite minimal, so I chose to keep the plot themes simple to allow the bright colors to stand out. This involved removing legends, axis text, axis lines, and background grids, as previously mentioned. Most of these elements weren‚Äôt essential for conveying meaning and could be effectively replaced with annotations in the final graphic.\n\n\nI had a lot of fun experimenting with colors! As mentioned earlier, I chose a photograph of a smoggy downtown Los Angeles, which features distinct layers of smog and sky. Using the color picker in Affinity, I extracted the colors from the image. I then checked them for colorblind accessibility and tested them on a grayscale to ensure they remained distinguishable. To further improve accessibility, I adjusted the saturation and opacity. I‚Äôm really happy with the palette I ended up with‚Äîit transitions from a cool blue to a bright terracotta, capturing the sky in LA. The cool-to-warm gradient also helps illustrate the progression of pollution levels, from low to high.\n\n\nI used two fonts throughout my infographic to ensure consistency and readability. Montserrat was reserved for the main title, while Open Sans was used for all other text. Both are sans-serif fonts, chosen for their clarity and modern aesthetic‚Äîa subtle contrast to the theme of polluted air. To enhance readability and emphasize important details, I used bold text, often paired with color, to highlight key points in annotations and draw attention to critical statistics.\n\n\nI designed the infographic to guide the viewer‚Äôs eyes in a natural reading flow‚Äîmoving from left to right and then down, similar to reading a book. However, I was also mindful that not everyone follows the same reading pattern, so I ensured that each graph could stand alone and be understood in any order. That said, I placed the illustration of PM2.5 and its context right at the top, just below the title, as I felt it was crucial for understanding the rest of the infographic.\n\n\nI spent a lot of time refining the story to ensure it naturally guides the viewer toward key insights while still allowing for personal interpretation. However, I did provide context through the header, the PM2.5 illustration, and concise plot annotations. Instead of over-annotating with additional explanations or takeaways, I used select highlights to guide the reader and let the data speak for itself.\n\n\nWhile this project initially started as an exploration without a specific message in mind, a clear takeaway emerged: PM2.5 pollution in Los Angeles is a significant issue, with distinct spatial and temporal patterns. The infographic serves more as an introductory overview (think ‚Äî PM2.5 Pollution 101) rather than an in-depth analysis, providing viewers with a foundational understanding of the issue.\n\n\nAs mentioned earlier, I created my own color palette based on a photo of smog. Some of the colors were too similar, which could cause accessibility issues for viewers with color blindness or in grayscale. To address this, I adjusted the saturation of certain colors to create more contrast. I also made sure to avoid placing colors that were too similar next to each other, unless they were part of a gradient. Additionally, I added alt text to all of my visuals to further ensure accessibility for all viewers.\n\n\nI knew I wanted to incorporate a DEI aspect into my choropleth map of PM2.5 pollution in Los Angeles. When I noticed pollution hotspots in Reseda and Central Los Angeles, I decided to check if these areas also ranked high on the CalEnviroScreen 4.0 percentile range. The CalEnviroScreen 4.0 percentile range is a tool used to assess the cumulative environmental, health, and socioeconomic impacts in California. Areas are ranked based on factors like water quality, proximity to hazardous waste sites, and poverty levels. Both Reseda and Central Los Angeles ranked very high, indicating they had high cumulative impacts, including both high PM2.5 levels and significant socioeconomic stressors. To represent this, I initially created a bivariate map. However, I faced challenges trying to explain what the CalEnviroScreen percentile range meant in the context of an infographic. To make this easier to interpret, I simplified the map by focusing solely on PM2.5 pollution and poverty. Despite this, I still found it difficult to display the data in a clear and understandable way, as I would need to explain each of the combinations (high pollution, high poverty; low pollution, high poverty, etc.) within the map for it to make sense to viewers. Since the bivariate map and the pollution distribution map looked very similar, I decided to show just the distribution of PM2.5 pollution in Los Angeles, and note the poverty aspect into the annotations. I think this made it easier to understand, but still hits on the major environmental justice issue at play."
  },
  {
    "objectID": "portfolio/hotspot_analysis/index.html",
    "href": "portfolio/hotspot_analysis/index.html",
    "title": "Mapping Sea Lion Conservation: Identifying Hotspots and Coldspots",
    "section": "",
    "text": "Background:\nEffective allocation of conservation resources for the California sea lion (Zalophus californianus) and Steller sea lion (Eumetopias jubatus) hinges on identifying areas of high conservation priority. Distinguishing between ‚Äúhotspots,‚Äù which represent regions with high species richness under high threat levels, and coldspots, areas of similarly high species richness with lower associated threats, is key to this process. Hotspots may demand more urgent attention, while coldspots may represent zones of population stability, potentially serving as long-term refugia. In this study, we considered a range of threats to sea lion populations, as detailed in Appendix A.\n\n\n\nLeft: Adult California sea lion (NOAA Fisheries) Right: Steller sea lion (National Geographic)\n\n\n\n\nProblem:\nStrategic conservation planning often involves reconciling different stakeholder priorities. A key debate centers on whether to allocate limited resources toward conserving areas of high biodiversity that are under immediate threat (hotspots) or protecting species-rich regions that face fewer immediate risks (coldspots). With constraints on both funding and capacity, it is crucial to adopt a data-driven approach that balances these competing objectives.\n\n\nApproach:\nWe began by creating a comprehensive species richness layer by summing the individual species distribution layers. Probabilities were converted to binary presence/absence data, where presence (1) represented the upper 50th percentile and absence (0) the lower 50th percentile. ‚ÄúNo data‚Äù cells were recoded as 0 to simplify subsequent raster calculations.\nThe combined species richness layer was then simplified to show areas of presence for either or both species. Specifically, values of 0 were reclassified as ‚ÄòNODATA,‚Äô and values of 1 and 2 (indicating the presence of one or both species) were reclassified as 1.\nNext, a threat layer was introduced, representing the cumulative impact of various threats on the marine environment. This layer was categorized into five equal-area quantiles, from which we generated a high-threat layer by reclassifying all but the highest quantile to ‚ÄòNODATA.‚Äô We used the same process to create a low-threat layer, isolating the lowest quantile. We ensured consistency by matching cell size and extent between the threat and species richness layers. Finally, we intersected the high and low-threat rasters with the sea lion species richness layer to show areas of high-threat (hotspots) and low-threat (coldspots) relative to sea lion distribution.\n\n\nResults:\nAs shown in Figure 1, sea lion hotspots are concentrated in the northern portion of their range, particularly along the Pacific Northwest coast. In contrast, cold spots are predominantly found in the southern portion of the species range, off the coast of Southern California and Baja.\n\n\n\nFigure 1. Sealion (Zalophus californianus and Eumetopias jubatus) Hotspots and Coldspots. Red represents hotspots or areas with high sealion biodiversity and high threat. Blue represents the coldspots or areas with high sealion biodiversity and low threat.\n\n\n\n\nConclusions:\nOur results present a clear distinction in the distribution of threats relative to areas with high sea lion species richness. The northern population is under greater threat and, therefore, may require more urgent conservation action. To mitigate these risks, conservation efforts should be focused in the northern range where more biodiverse populations are facing greater threats. However, it is also important to consider conservation actions in coldspots to prevent future threats, and ensure population resilience. Additionally, safeguarding coldspot zones may create refuge areas for sea lions, helping to maintain overall population stability."
  }
]